@Preamble{ " \newcommand{\noop}[1]{} " }


@article{brodrick_uncovering_2019,
	title = {Uncovering {Ecological} {Patterns} with {Convolutional} {Neural} {Networks}},
	volume = {34},
	issn = {01695347},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169534719300862},
	doi = {10.1016/j.tree.2019.03.006},
	language = {en},
	number = {8},
	urldate = {2021-07-30},
	journal = {Trends in Ecology \& Evolution},
	author = {Brodrick, Philip G. and Davies, Andrew B. and Asner, Gregory P.},
	month = aug,
	year = {2019},
	pages = {734--745},
	file = {Brodrick et al. - 2019 - Uncovering Ecological Patterns with Convolutional .pdf:/Users/oliviergimenez/Zotero/storage/AVHP39E2/Brodrick et al. - 2019 - Uncovering Ecological Patterns with Convolutional .pdf:application/pdf},
}

@article{lamba_deep_2019,
	title = {Deep learning for environmental conservation},
	volume = {29},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982219310322},
	doi = {10.1016/j.cub.2019.08.016},
	language = {en},
	number = {19},
	urldate = {2021-07-30},
	journal = {Current Biology},
	author = {Lamba, Aakash and Cassey, Phillip and Segaran, Ramesh Raja and Koh, Lian Pin},
	month = oct,
	year = {2019},
	pages = {R977--R982},
	file = {Lamba et al. - 2019 - Deep learning for environmental conservation.pdf:/Users/oliviergimenez/Zotero/storage/TBZDWFQ7/Lamba et al. - 2019 - Deep learning for environmental conservation.pdf:application/pdf},
}

@article{weinstein_computer_2018,
	title = {A computer vision for animal ecology},
	volume = {87},
	issn = {00218790},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/1365-2656.12780},
	doi = {10.1111/1365-2656.12780},
	language = {en},
	number = {3},
	urldate = {2021-07-30},
	journal = {Journal of Animal Ecology},
	author = {Weinstein, Ben G.},
	editor = {Prugh, Laura},
	month = may,
	year = {2018},
	pages = {533--545},
	file = {Weinstein - 2018 - A computer vision for animal ecology.pdf:/Users/oliviergimenez/Zotero/storage/9TYSGDGD/Weinstein - 2018 - A computer vision for animal ecology.pdf:application/pdf},
}

@article{beery_recognition_2018,
	title = {Recognition in {Terra} {Incognita}},
	url = {http://arxiv.org/abs/1807.04975},
	abstract = {It is desirable for detection and classification algorithms to generalize to unfamiliar environments, but suitable benchmarks for quantitatively studying this phenomenon are not yet available. We present a dataset designed to measure recognition generalization to novel environments. The images in our dataset are harvested from twenty camera traps deployed to monitor animal populations. Camera traps are fixed at one location, hence the background changes little across images; capture is triggered automatically, hence there is no human bias. The challenge is learning recognition in a handful of locations, and generalizing animal detection and classification to new locations where no training data is available. In our experiments state-of-the-art algorithms show excellent performance when tested at the same location where they were trained. However, we find that generalization to new locations is poor, especially for classification systems.},
	language = {en},
	urldate = {2021-07-30},
	journal = {arXiv:1807.04975 [cs, q-bio]},
	author = {Beery, Sara and van Horn, Grant and Perona, Pietro},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.04975},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Populations and Evolution},
	file = {Beery et al. - 2018 - Recognition in Terra Incognita.pdf:/Users/oliviergimenez/Zotero/storage/96XY2GMR/Beery et al. - 2018 - Recognition in Terra Incognita.pdf:application/pdf},
}

@article{willi_identifying_2019,
	title = {Identifying animal species in camera trap images using deep learning and citizen science},
	volume = {10},
	issn = {2041-210X, 2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13099},
	doi = {10.1111/2041-210X.13099},
	language = {en},
	number = {1},
	urldate = {2021-07-30},
	journal = {Methods in Ecology and Evolution},
	author = {Willi, Marco and Pitman, Ross T. and Cardoso, Anabelle W. and Locke, Christina and Swanson, Alexandra and Boyer, Amy and Veldthuis, Marten and Fortson, Lucy},
	editor = {Gaggiotti, Oscar},
	month = jan,
	year = {2019},
	pages = {80--91},
	file = {Willi et al. - 2019 - Identifying animal species in camera trap images u.pdf:/Users/oliviergimenez/Zotero/storage/TKAYQZB8/Willi et al. - 2019 - Identifying animal species in camera trap images u.pdf:application/pdf},
}

@article{tabak_machine_2019,
	title = {Machine learning to classify animal species in camera trap images: {Applications} in ecology},
	volume = {10},
	issn = {2041-210X, 2041-210X},
	shorttitle = {Machine learning to classify animal species in camera trap images},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13120},
	doi = {10.1111/2041-210X.13120},
	language = {en},
	number = {4},
	urldate = {2021-07-30},
	journal = {Methods in Ecology and Evolution},
	author = {Tabak, Michael A. and Norouzzadeh, Mohammad S. and Wolfson, David W. and Sweeney, Steven J. and Vercauteren, Kurt C. and Snow, Nathan P. and Halseth, Joseph M. and Di Salvo, Paul A. and Lewis, Jesse S. and White, Michael D. and Teton, Ben and Beasley, James C. and Schlichting, Peter E. and Boughton, Raoul K. and Wight, Bethany and Newkirk, Eric S. and Ivan, Jacob S. and Odell, Eric A. and Brook, Ryan K. and Lukacs, Paul M. and Moeller, Anna K. and Mandeville, Elizabeth G. and Clune, Jeff and Miller, Ryan S.},
	editor = {Photopoulou, Theoni},
	month = apr,
	year = {2019},
	pages = {585--590},
	file = {Tabak et al. - 2019 - Machine learning to classify animal species in cam.pdf:/Users/oliviergimenez/Zotero/storage/L8MFLYYL/Tabak et al. - 2019 - Machine learning to classify animal species in cam.pdf:application/pdf},
}

@article{schneider_past_2019,
	title = {Past, present and future approaches using computer vision for animal re‐identification from camera trap data},
	volume = {10},
	issn = {2041-210X, 2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13133},
	doi = {10.1111/2041-210X.13133},
	language = {en},
	number = {4},
	urldate = {2021-07-30},
	journal = {Methods in Ecology and Evolution},
	author = {Schneider, Stefan and Taylor, Graham W. and Linquist, Stefan and Kremer, Stefan C.},
	editor = {O’Hara, Robert B.},
	month = apr,
	year = {2019},
	pages = {461--470},
	file = {Schneider et al. - 2019 - Past, present and future approaches using computer.pdf:/Users/oliviergimenez/Zotero/storage/GXYIE9QU/Schneider et al. - 2019 - Past, present and future approaches using computer.pdf:application/pdf},
}

@article{christin_applications_2019,
	title = {Applications for deep learning in ecology},
	volume = {10},
	issn = {2041-210X, 2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13256},
	doi = {10.1111/2041-210X.13256},
	language = {en},
	number = {10},
	urldate = {2021-07-30},
	journal = {Methods in Ecology and Evolution},
	author = {Christin, Sylvain and Hervet, Éric and Lecomte, Nicolas},
	editor = {Ye, Hao},
	month = oct,
	year = {2019},
	pages = {1632--1644},
	file = {Christin et al. - 2019 - Applications for deep learning in ecology.pdf:/Users/oliviergimenez/Zotero/storage/MMVYQTQQ/Christin et al. - 2019 - Applications for deep learning in ecology.pdf:application/pdf},
}

@article{ferreira_deep_2020,
	title = {Deep learning‐based methods for individual recognition in small birds},
	volume = {11},
	issn = {2041-210X, 2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13436},
	doi = {10.1111/2041-210X.13436},
	language = {en},
	number = {9},
	urldate = {2021-07-30},
	journal = {Methods in Ecology and Evolution},
	author = {Ferreira, André C. and Silva, Liliana R. and Renna, Francesco and Brandl, Hanja B. and Renoult, Julien P. and Farine, Damien R. and Covas, Rita and Doutrelant, Claire},
	editor = {Codling, Edward},
	month = sep,
	year = {2020},
	pages = {1072--1085},
	file = {Ferreira et al. - 2020 - Deep learning‐based methods for individual recogni.pdf:/Users/oliviergimenez/Zotero/storage/WS5R69TC/Ferreira et al. - 2020 - Deep learning‐based methods for individual recogni.pdf:application/pdf},
}

@article{norouzzadeh_deep_2021,
	title = {A deep active learning system for species identification and counting in camera trap images},
	volume = {12},
	issn = {2041-210X, 2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13504},
	doi = {10.1111/2041-210X.13504},
	language = {en},
	number = {1},
	urldate = {2021-07-30},
	journal = {Methods in Ecology and Evolution},
	author = {Norouzzadeh, Mohammad Sadegh and Morris, Dan and Beery, Sara and Joshi, Neel and Jojic, Nebojsa and Clune, Jeff},
	editor = {Schofield, Matthew},
	month = jan,
	year = {2021},
	pages = {150--161},
	file = {Norouzzadeh et al. - 2021 - A deep active learning system for species identifi.pdf:/Users/oliviergimenez/Zotero/storage/WNXGEBUH/Norouzzadeh et al. - 2021 - A deep active learning system for species identifi.pdf:application/pdf},
}

@article{bogucki_applying_2019,
	title = {Applying deep learning to right whale photo identification},
	volume = {33},
	issn = {0888-8892, 1523-1739},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cobi.13226},
	doi = {10.1111/cobi.13226},
	abstract = {Photo identification is an important tool for estimating abundance and monitoring population trends over time. However, manually matching photographs to known individuals is time-consuming. Motivated by recent developments in image recognition, we hosted a data science challenge on the crowdsourcing platform Kaggle to automate the identification of endangered North Atlantic right whales (Eubalaena glacialis). The winning solution automatically identified individual whales with 87\% accuracy with a series of convolutional neural networks to identify the region of interest on an image, rotate, crop, and create standardized photographs of uniform size and orientation and then identify the correct individual whale from these passport-like photographs. Recent advances in deep learning coupled with this fully automated workflow have yielded impressive results and have the potential to revolutionize traditional methods for the collection of data on the abundance and distribution of wild populations. Presenting these results to a broad audience should further bridge the gap between the data science and conservation science communities.},
	language = {en},
	number = {3},
	urldate = {2021-07-30},
	journal = {Conservation Biology},
	author = {Bogucki, Robert and Cygan, Marek and Khan, Christin Brangwynne and Klimek, Maciej and Milczek, Jan Kanty and Mucha, Marcin},
	month = jun,
	year = {2019},
	pages = {676--684},
	file = {Bogucki et al. - 2019 - Applying deep learning to right whale photo identi.pdf:/Users/oliviergimenez/Zotero/storage/KCYYFQVY/Bogucki et al. - 2019 - Applying deep learning to right whale photo identi.pdf:application/pdf},
}

@article{chen_study_2020,
	title = {A study on giant panda recognition based on images of a large proportion of captive pandas},
	volume = {10},
	issn = {2045-7758, 2045-7758},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/ece3.6152},
	doi = {10.1002/ece3.6152},
	language = {en},
	number = {7},
	urldate = {2021-07-30},
	journal = {Ecology and Evolution},
	author = {Chen, Peng and Swarup, Pranjal and Matkowski, Wojciech Michal and Kong, Adams Wai Kin and Han, Su and Zhang, Zhihe and Rong, Hou},
	month = apr,
	year = {2020},
	pages = {3561--3573},
	file = {Chen et al. - 2020 - A study on giant panda recognition based on images.pdf:/Users/oliviergimenez/Zotero/storage/CZIY58XU/Chen et al. - 2020 - A study on giant panda recognition based on images.pdf:application/pdf},
}

@article{tabak_improving_2020,
	title = {Improving the accessibility and transferability of machine learning algorithms for identification of animals in camera trap images: {MLWIC2}},
	volume = {10},
	issn = {2045-7758, 2045-7758},
	shorttitle = {Improving the accessibility and transferability of machine learning algorithms for identification of animals in camera trap images},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/ece3.6692},
	doi = {10.1002/ece3.6692},
	language = {en},
	number = {19},
	urldate = {2021-07-30},
	journal = {Ecology and Evolution},
	author = {Tabak, Michael A. and Norouzzadeh, Mohammad S. and Wolfson, David W. and Newton, Erica J. and Boughton, Raoul K. and Ivan, Jacob S. and Odell, Eric A. and Newkirk, Eric S. and Conrey, Reesa Y. and Stenglein, Jennifer and Iannarilli, Fabiola and Erb, John and Brook, Ryan K. and Davis, Amy J. and Lewis, Jesse and Walsh, Daniel P. and Beasley, James C. and VerCauteren, Kurt C. and Clune, Jeff and Miller, Ryan S.},
	month = oct,
	year = {2020},
	pages = {10374--10383},
	file = {Tabak et al. - 2020 - Improving the accessibility and transferability of.pdf:/Users/oliviergimenez/Zotero/storage/JWLKCD74/Tabak et al. - 2020 - Improving the accessibility and transferability of.pdf:application/pdf},
}

@article{bolt_educating_2021,
	title = {Educating the future generation of researchers: {A} cross-disciplinary survey of trends in analysis methods},
	volume = {19},
	issn = {1545-7885},
	shorttitle = {Educating the future generation of researchers},
	url = {https://dx.plos.org/10.1371/journal.pbio.3001313},
	doi = {10.1371/journal.pbio.3001313},
	abstract = {Methods for data analysis in the biomedical, life, and social (BLS) sciences are developing at a rapid pace. At the same time, there is increasing concern that education in quantitative methods is failing to adequately prepare students for contemporary research. These trends have led to calls for educational reform to undergraduate and graduate quantitative research method curricula. We argue that such reform should be based on data-driven insights into within- and cross-disciplinary use of analytic methods. Our survey of peer-reviewed literature analyzed approximately 1.3 million openly available research articles to monitor the cross-disciplinary mentions of analytic methods in the past decade. We applied data-driven text mining analyses to the “Methods” and “Results” sections of a large subset of this corpus to identify trends in analytic method mentions shared across disciplines, as well as those unique to each discipline. We found that the
              t
              test, analysis of variance (ANOVA), linear regression, chi-squared test, and other classical statistical methods have been and remain the most mentioned analytic methods in biomedical, life science, and social science research articles. However, mentions of these methods have declined as a percentage of the published literature between 2009 and 2020. On the other hand, multivariate statistical and machine learning approaches, such as artificial neural networks (ANNs), have seen a significant increase in the total share of scientific publications. We also found unique groupings of analytic methods associated with each BLS science discipline, such as the use of structural equation modeling (SEM) in psychology, survival models in oncology, and manifold learning in ecology. We discuss the implications of these findings for education in statistics and research methods, as well as within- and cross-disciplinary collaboration.},
	language = {en},
	number = {7},
	urldate = {2021-07-30},
	journal = {PLOS Biology},
	author = {Bolt, Taylor and Nomi, Jason S. and Bzdok, Danilo and Uddin, Lucina Q.},
	editor = {Dirnagl, Ulrich},
	month = jul,
	year = {2021},
	pages = {e3001313},
	file = {Bolt et al. - 2021 - Educating the future generation of researchers A .pdf:/Users/oliviergimenez/Zotero/storage/V8Q8RZ4H/Bolt et al. - 2021 - Educating the future generation of researchers A .pdf:application/pdf},
}

@article{miele_revisiting_2021,
	title = {Revisiting animal photo‐identification using deep metric learning and network analysis},
	volume = {12},
	issn = {2041-210X, 2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.13577},
	doi = {10.1111/2041-210X.13577},
	language = {en},
	number = {5},
	urldate = {2021-07-30},
	journal = {Methods in Ecology and Evolution},
	author = {Miele, Vincent and Dussert, Gaspard and Spataro, Bruno and Chamaillé‐Jammes, Simon and Allainé, Dominique and Bonenfant, Christophe},
	editor = {Freckleton, Robert},
	month = may,
	year = {2021},
	pages = {863--873},
	file = {Miele et al. - 2021 - Revisiting animal photo‐identification using deep .pdf:/Users/oliviergimenez/Zotero/storage/35S9AH3Z/Miele et al. - 2021 - Revisiting animal photo‐identification using deep .pdf:application/pdf},
}

@article{thompson_finfindr_2021,
	title = {{finFindR}: {Automated} recognition and identification of marine mammal dorsal fins using residual convolutional neural networks},
	issn = {0824-0469, 1748-7692},
	shorttitle = {{\textless}span style="font-variant},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/mms.12849},
	doi = {10.1111/mms.12849},
	abstract = {Photographic identification is an essential research and management tool for marine mammal scientists. However, manual identification of individuals is time-consuming. To shorten processing times, we developed finFindR, an opensource application that uses a series of neural networks to autonomously locate dorsal fins in unedited field images, quantify an individual's unique fin characteristics, and match them to an existing photograph catalog. During a blind test comparing manual searching to finFindR for common bottlenose dolphin (Tursiops Tursiops truncatus) photographs, experienced photo-identification technicians achieved similar match rates but examined an order of magnitude fewer photographs using finFindR (an average of 10 required with finFindR versus 124 with manual search). In those tests, the correct identity was ranked in the first position in 88\% of cases and was within the top 50 ranked positions in 97\% of cases. Our observations suggest that finFindR's matching capabilities are robust to moderate variation in image quality and fin distinctiveness. Importantly, finFindR allows users to build a catalog of known individuals through time and match an unlimited number of individuals instead of being restricted to a predefined set. finFindR's convolutional neural networks could be re-trained to identify members of many marine mammal species without altering finFindR's inherent structure.},
	language = {en},
	urldate = {2021-07-30},
	journal = {Marine Mammal Science},
	author = {Thompson, Jaime W. and Zero, Victoria H. and Schwacke, Lori H. and Speakman, Todd R. and Quigley, Brian M. and Morey, Jeanine S. and McDonald, Trent L.},
	month = jul,
	year = {2021},
	pages = {mms.12849},
	file = {Thompson et al. - 2021 -  finFind.pdf:/Users/oliviergimenez/Zotero/storage/NI88FPG3/Thompson et al. - 2021 -  finFind.pdf:application/pdf},
}


@article{lahoz-monfort_comprehensive_2021,
	title = {A {Comprehensive} {Overview} of {Technologies} for {Species} and {Habitat} {Monitoring} and {Conservation}},
	issn = {0006-3568, 1525-3244},
	url = {https://academic.oup.com/bioscience/advance-article/doi/10.1093/biosci/biab073/6322306},
	doi = {10.1093/biosci/biab073},
	abstract = {The range of technologies currently used in biodiversity conservation is staggering, with innovative uses often adopted from other disciplines and being trialed in the field. We provide the first comprehensive overview of the current (2020) landscape of conservation technology, encompassing technologies for monitoring wildlife and habitats, as well as for on-the-ground conservation management (e.g., fighting illegal activities). We cover both established technologies (routinely deployed in conservation, backed by substantial field experience and scientific literature) and novel technologies or technology applications (typically at trial stage, only recently used in conservation), providing examples of conservation applications for both types. We describe technologies that deploy sensors that are fixed or portable, attached to vehicles (terrestrial, aquatic, or airborne) or to animals (biologging), complemented with a section on wildlife tracking. The last two sections cover actuators and computing (including web platforms, algorithms, and artificial intelligence).},
	language = {en},
	urldate = {2021-07-30},
	journal = {BioScience},
	author = {Lahoz-Monfort, José J and Magrath, Michael J L},
	year = {2021},
	file = {Lahoz-Monfort et Magrath - 2021 - A Comprehensive Overview of Technologies for Speci.pdf:/Users/oliviergimenez/Zotero/storage/GI79AVA2/Lahoz-Monfort et Magrath - 2021 - A Comprehensive Overview of Technologies for Speci.pdf:application/pdf},
}
